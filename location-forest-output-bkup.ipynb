{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KS9rO86je_1s"
   },
   "source": [
    "Build Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Xabu4LABA-aL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfAYs6Lvfpne"
   },
   "source": [
    "Load input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "txuoQ7yQO8wK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0       Name    Fips      State  State ANSI   Ag District  \\\n",
      "0               0  aleutians  2013.0        NaN         NaN           NaN   \n",
      "1               1  aleutians  2016.0        NaN         NaN           NaN   \n",
      "2               2  anchorage  2020.0        NaN         NaN           NaN   \n",
      "3               3     bethel  2050.0        NaN         NaN           NaN   \n",
      "4               4    bristol  2060.0        NaN         NaN           NaN   \n",
      "...           ...        ...     ...        ...         ...           ...   \n",
      "14696       14696        NaN     NaN  WISCONSIN        55.0       CENTRAL   \n",
      "14697       14697        NaN     NaN  WISCONSIN        55.0  EAST CENTRAL   \n",
      "14698       14698        NaN     NaN  WISCONSIN        55.0  WEST CENTRAL   \n",
      "14699       14699        NaN     NaN  WISCONSIN        55.0  WEST CENTRAL   \n",
      "14700       14700        NaN     NaN    WYOMING        56.0     NORTHWEST   \n",
      "\n",
      "       Ag District Code       County  County ANSI   2002  ...   2022     FIPS  \\\n",
      "0                   NaN          NaN          NaN    NaN  ...    NaN      NaN   \n",
      "1                   NaN          NaN          NaN    NaN  ...    NaN      NaN   \n",
      "2                   NaN          NaN          NaN    NaN  ...    NaN      NaN   \n",
      "3                   NaN          NaN          NaN    NaN  ...    NaN      NaN   \n",
      "4                   NaN          NaN          NaN    NaN  ...    NaN      NaN   \n",
      "...                 ...          ...          ...    ...  ...    ...      ...   \n",
      "14696              50.0   green lake         47.0  207.0  ...  335.0  55047.0   \n",
      "14697              60.0  fond du lac         39.0  257.0  ...  135.0  55039.0   \n",
      "14698              40.0   eau claire         35.0  174.0  ...  574.0  55035.0   \n",
      "14699              40.0    la crosse         63.0   88.0  ...   58.0  55063.0   \n",
      "14700              10.0  hot springs         17.0  517.0  ...  656.0  56017.0   \n",
      "\n",
      "            county      state  Total_Area_km2 2002_bee_density  \\\n",
      "0              NaN        NaN             NaN              NaN   \n",
      "1              NaN        NaN             NaN              NaN   \n",
      "2              NaN        NaN             NaN              NaN   \n",
      "3              NaN        NaN             NaN              NaN   \n",
      "4              NaN        NaN             NaN              NaN   \n",
      "...            ...        ...             ...              ...   \n",
      "14696   green lake  wisconsin      984.517438         0.210255   \n",
      "14697  fond du lac  wisconsin     1983.521079         0.129568   \n",
      "14698   eau claire  wisconsin     1671.059794         0.104126   \n",
      "14699    la crosse  wisconsin     1243.325479         0.070778   \n",
      "14700  hot springs    wyoming     5196.554069         0.099489   \n",
      "\n",
      "      2007_bee_density  2012_bee_density  2017_bee_density  2022_bee_density  \n",
      "0                  NaN               NaN               NaN               NaN  \n",
      "1                  NaN               NaN               NaN               NaN  \n",
      "2                  NaN               NaN               NaN               NaN  \n",
      "3                  NaN               NaN               NaN               NaN  \n",
      "4                  NaN               NaN               NaN               NaN  \n",
      "...                ...               ...               ...               ...  \n",
      "14696         0.100557          0.112746          0.113761          0.340268  \n",
      "14697         0.082177          0.094781          0.118980          0.068061  \n",
      "14698         0.077197          0.159779          0.206456          0.343495  \n",
      "14699         0.090081          0.087668          0.054692          0.046649  \n",
      "14700         0.099489          0.099489          0.001155          0.126238  \n",
      "\n",
      "[14701 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "df_fips=pd.read_csv('../../input/bees/targets/bees-targets_new.csv')\n",
    "\n",
    "print(df_fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available states: [nan 'ALABAMA' 'GEORGIA' 'WEST VIRGINIA' 'TENNESSEE' 'IOWA' 'KANSAS'\n",
      " 'KENTUCKY' 'MISSOURI' 'NEBRASKA' 'OHIO' 'PENNSYLVANIA' 'ARKANSAS'\n",
      " 'FLORIDA' 'ILLINOIS' 'MICHIGAN' 'MISSISSIPPI' 'SOUTH CAROLINA' 'TEXAS'\n",
      " 'OKLAHOMA' 'NORTH CAROLINA' 'VIRGINIA' 'INDIANA' 'MINNESOTA'\n",
      " 'SOUTH DAKOTA' 'IDAHO' 'LOUISIANA' 'MAINE' 'MASSACHUSETTS' 'NEW YORK'\n",
      " 'VERMONT' 'WASHINGTON' 'COLORADO' 'OREGON' 'WISCONSIN' 'MONTANA'\n",
      " 'MARYLAND' 'UTAH' 'RHODE ISLAND' 'NEW HAMPSHIRE' 'NEVADA' 'NEW MEXICO'\n",
      " 'NORTH DAKOTA' 'WYOMING' 'CALIFORNIA' 'NEW JERSEY' 'ARIZONA' 'DELAWARE'\n",
      " 'HAWAII' 'CONNECTICUT']\n",
      "Available years: [2002, 2007, 2012, 2017]\n"
     ]
    }
   ],
   "source": [
    "# Check available states and years in the dataset\n",
    "print(\"Available states:\", df_fips['State'].unique())\n",
    "print(\"Available years:\", [2002, 2007, 2012, 2017])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the state (e.g., MAINE): MAINE\n",
      "Enter the year (2002, 2007, 2012, 2017, or 2022): 2007\n",
      "Filtered data for MAINE in 2007:\n",
      "     Unnamed: 0        Name    Fips  State  State ANSI Ag District  \\\n",
      "141         141    franklin  1059.0  MAINE        23.0       SOUTH   \n",
      "437         437  washington  1129.0  MAINE        23.0     CENTRAL   \n",
      "596         596    franklin  5047.0  MAINE        23.0       SOUTH   \n",
      "748         748     lincoln  5079.0  MAINE        23.0       SOUTH   \n",
      "976         976  washington  5143.0  MAINE        23.0     CENTRAL   \n",
      "\n",
      "     Ag District Code      County  County ANSI   2002  ...    FIPS  \\\n",
      "141              30.0    franklin          7.0   78.0  ...  1059.0   \n",
      "437              20.0  washington         29.0  346.0  ...  1129.0   \n",
      "596              30.0    franklin          7.0   78.0  ...  5047.0   \n",
      "748              30.0     lincoln         15.0  517.0  ...  5079.0   \n",
      "976              20.0  washington         29.0  346.0  ...  5143.0   \n",
      "\n",
      "         county     state  Total_Area_km2  2002_bee_density 2007_bee_density  \\\n",
      "141    franklin   alabama     1674.485326          0.046581         0.042998   \n",
      "437  washington   alabama     2819.372979          0.122722         0.258568   \n",
      "596    franklin  arkansas     1606.071959          0.048566         0.044830   \n",
      "748     lincoln  arkansas     1475.702552          0.350342         0.022362   \n",
      "976  washington  arkansas     2466.244494          0.140294         0.295591   \n",
      "\n",
      "    2012_bee_density  2017_bee_density  2022_bee_density  label  \n",
      "141         0.097941          0.038818          0.043595      0  \n",
      "437         2.494172          0.168832          0.033695      0  \n",
      "596         0.102112          0.040471          0.045453      0  \n",
      "748         0.029139          0.136206          0.174832      0  \n",
      "976         2.851299          0.193006          0.038520      0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Prompt- user for input\n",
    "selected_state = input(\"Enter the state (e.g., MAINE): \").strip()\n",
    "\n",
    "selected_year = int(input(\"Enter the year (2002, 2007, 2012, 2017, or 2022): \").strip())\n",
    "\n",
    "# Filter the DataFrame based on the user input\n",
    "density_col = f'{selected_year}_bee_density'\n",
    "\n",
    "# Filter data\n",
    "df_filtered = df_fips[(df_fips['State'] == selected_state) & (df_fips[density_col].notna())].copy()\n",
    "\n",
    "# Create label based on top 20% bee density\n",
    "threshold = df_filtered[density_col].quantile(0.8)\n",
    "df_filtered['label'] = (df_filtered[density_col] > threshold).astype(int)\n",
    "\n",
    "# Display the filtered data\n",
    "print(f\"Filtered data for {selected_state} in {selected_year}:\")\n",
    "print(df_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Fips</th>\n",
       "      <th>State</th>\n",
       "      <th>State ANSI</th>\n",
       "      <th>Ag District</th>\n",
       "      <th>Ag District Code</th>\n",
       "      <th>County</th>\n",
       "      <th>County ANSI</th>\n",
       "      <th>2002</th>\n",
       "      <th>...</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>Total_Area_km2</th>\n",
       "      <th>2002_bee_density</th>\n",
       "      <th>2007_bee_density</th>\n",
       "      <th>2012_bee_density</th>\n",
       "      <th>2017_bee_density</th>\n",
       "      <th>2022_bee_density</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>franklin</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>MAINE</td>\n",
       "      <td>23.0</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>30.0</td>\n",
       "      <td>franklin</td>\n",
       "      <td>7.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>franklin</td>\n",
       "      <td>alabama</td>\n",
       "      <td>1674.485326</td>\n",
       "      <td>0.046581</td>\n",
       "      <td>0.042998</td>\n",
       "      <td>0.097941</td>\n",
       "      <td>0.038818</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>437</td>\n",
       "      <td>washington</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>MAINE</td>\n",
       "      <td>23.0</td>\n",
       "      <td>CENTRAL</td>\n",
       "      <td>20.0</td>\n",
       "      <td>washington</td>\n",
       "      <td>29.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>washington</td>\n",
       "      <td>alabama</td>\n",
       "      <td>2819.372979</td>\n",
       "      <td>0.122722</td>\n",
       "      <td>0.258568</td>\n",
       "      <td>2.494172</td>\n",
       "      <td>0.168832</td>\n",
       "      <td>0.033695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>596</td>\n",
       "      <td>franklin</td>\n",
       "      <td>5047.0</td>\n",
       "      <td>MAINE</td>\n",
       "      <td>23.0</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>30.0</td>\n",
       "      <td>franklin</td>\n",
       "      <td>7.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5047.0</td>\n",
       "      <td>franklin</td>\n",
       "      <td>arkansas</td>\n",
       "      <td>1606.071959</td>\n",
       "      <td>0.048566</td>\n",
       "      <td>0.044830</td>\n",
       "      <td>0.102112</td>\n",
       "      <td>0.040471</td>\n",
       "      <td>0.045453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>748</td>\n",
       "      <td>lincoln</td>\n",
       "      <td>5079.0</td>\n",
       "      <td>MAINE</td>\n",
       "      <td>23.0</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>30.0</td>\n",
       "      <td>lincoln</td>\n",
       "      <td>15.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5079.0</td>\n",
       "      <td>lincoln</td>\n",
       "      <td>arkansas</td>\n",
       "      <td>1475.702552</td>\n",
       "      <td>0.350342</td>\n",
       "      <td>0.022362</td>\n",
       "      <td>0.029139</td>\n",
       "      <td>0.136206</td>\n",
       "      <td>0.174832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>976</td>\n",
       "      <td>washington</td>\n",
       "      <td>5143.0</td>\n",
       "      <td>MAINE</td>\n",
       "      <td>23.0</td>\n",
       "      <td>CENTRAL</td>\n",
       "      <td>20.0</td>\n",
       "      <td>washington</td>\n",
       "      <td>29.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5143.0</td>\n",
       "      <td>washington</td>\n",
       "      <td>arkansas</td>\n",
       "      <td>2466.244494</td>\n",
       "      <td>0.140294</td>\n",
       "      <td>0.295591</td>\n",
       "      <td>2.851299</td>\n",
       "      <td>0.193006</td>\n",
       "      <td>0.038520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        Name    Fips  State  State ANSI Ag District  \\\n",
       "141         141    franklin  1059.0  MAINE        23.0       SOUTH   \n",
       "437         437  washington  1129.0  MAINE        23.0     CENTRAL   \n",
       "596         596    franklin  5047.0  MAINE        23.0       SOUTH   \n",
       "748         748     lincoln  5079.0  MAINE        23.0       SOUTH   \n",
       "976         976  washington  5143.0  MAINE        23.0     CENTRAL   \n",
       "\n",
       "     Ag District Code      County  County ANSI   2002  ...    FIPS  \\\n",
       "141              30.0    franklin          7.0   78.0  ...  1059.0   \n",
       "437              20.0  washington         29.0  346.0  ...  1129.0   \n",
       "596              30.0    franklin          7.0   78.0  ...  5047.0   \n",
       "748              30.0     lincoln         15.0  517.0  ...  5079.0   \n",
       "976              20.0  washington         29.0  346.0  ...  5143.0   \n",
       "\n",
       "         county     state  Total_Area_km2  2002_bee_density 2007_bee_density  \\\n",
       "141    franklin   alabama     1674.485326          0.046581         0.042998   \n",
       "437  washington   alabama     2819.372979          0.122722         0.258568   \n",
       "596    franklin  arkansas     1606.071959          0.048566         0.044830   \n",
       "748     lincoln  arkansas     1475.702552          0.350342         0.022362   \n",
       "976  washington  arkansas     2466.244494          0.140294         0.295591   \n",
       "\n",
       "    2012_bee_density  2017_bee_density  2022_bee_density  label  \n",
       "141         0.097941          0.038818          0.043595      0  \n",
       "437         2.494172          0.168832          0.033695      0  \n",
       "596         0.102112          0.040471          0.045453      0  \n",
       "748         0.029139          0.136206          0.174832      0  \n",
       "976         2.851299          0.193006          0.038520      0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    97\n",
      "1    24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_counts = df_filtered['label'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedure to run a single state\n",
    "Take Maine as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Name', 'Fips', 'State', 'State ANSI', 'Ag District',\n",
       "       'Ag District Code', 'County', 'County ANSI', '2002', '2007', '2012',\n",
       "       '2017', '2022', 'FIPS', 'county', 'state', 'Total_Area_km2',\n",
       "       '2002_bee_density', '2007_bee_density', '2012_bee_density',\n",
       "       '2017_bee_density', '2022_bee_density', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ML MODEL-1ST HALF (ONE HOT ENCODING)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "\n",
    "# Define Features and Target with One-Hot Encoding\n",
    "#df_full_model = df_fips[df_fips['State'] == 'MAINE']  # Filter for Maine\n",
    "categorical_columns = ['County', 'State', 'Ag District'] # Categorical columns for one-hot encoding\n",
    "\n",
    "# Apply one-hot encoding\n",
    "df_encoded = pd.get_dummies(df_filtered, columns=categorical_columns, drop_first=True)\n",
    "df_encoded.columns\n",
    "df_filtered.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 50, max_depth = 10, min_samples_split = 10, min_samples_leaf = 5\n",
      "Accuracy score on train set = 0.9583333333333334 and accuracy score on test set = 0.92\n",
      "f1 score on train set = 0.8823529411764706 and f1 score on test set = 0.75\n",
      "Recall score on train set = 0.7894736842105263 and recall score on test set = 0.6\n",
      "Precision score on train set = 1.0 and precision score on test set = 1.0\n"
     ]
    }
   ],
   "source": [
    "#MODEL-2ND HALF (TRAINING AND EVALUATION)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_encoded.drop(columns=['Unnamed: 0','Name','State ANSI',\n",
    "       'Ag District Code', 'County ANSI', '2002', '2007', '2012',\n",
    "       '2017', '2022', 'FIPS', 'county', 'state', 'Total_Area_km2',\n",
    "       '2002_bee_density', '2007_bee_density', '2012_bee_density',\n",
    "       '2017_bee_density', 'label'])  # Drop non-feature columns\n",
    "y = df_encoded['label']  # Target variable\n",
    "\n",
    "X.columns\n",
    "# Split Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Standardize Features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Perform Grid Search for Random Forest Hyperparameters\n",
    "rfc = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [5, 10, 25],\n",
    "    'min_samples_split': [10, 20],\n",
    "    'min_samples_leaf': [5, 10]\n",
    "}\n",
    "rfcs = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "rfcs.fit(X_train, y_train)\n",
    "\n",
    "# Save optimal parameters\n",
    "n_estimator = rfcs.best_params_['n_estimators']\n",
    "depth = rfcs.best_params_['max_depth']\n",
    "min_split = rfcs.best_params_['min_samples_split']\n",
    "min_leaf = rfcs.best_params_['min_samples_leaf']\n",
    "print(f'n_estimators = {n_estimator}, max_depth = {depth}, min_samples_split = {min_split}, min_samples_leaf = {min_leaf}')\n",
    "\n",
    "# Fit a new Random Forest with optimal parameters\n",
    "opt_rfc = RandomForestClassifier(\n",
    "    n_estimators=n_estimator,\n",
    "    max_depth=depth,\n",
    "    min_samples_split=min_split,\n",
    "    min_samples_leaf=min_leaf,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "opt_rfc.fit(X_train, y_train)\n",
    "pred_train = opt_rfc.predict(X_train)\n",
    "pred_test = opt_rfc.predict(X_test)\n",
    "\n",
    "# Evaluate Model\n",
    "accu_train = accuracy_score(y_train, pred_train)\n",
    "accu_test = accuracy_score(y_test, pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train, pred_train)\n",
    "f1_test = f1_score(y_test, pred_test)\n",
    "\n",
    "recall_train = recall_score(y_train, pred_train)\n",
    "recall_test = recall_score(y_test, pred_test)\n",
    "\n",
    "precision_train = precision_score(y_train, pred_train)\n",
    "precision_test = precision_score(y_test, pred_test)\n",
    "\n",
    "# Print Results\n",
    "print(f'Accuracy score on train set = {accu_train} and accuracy score on test set = {accu_test}')\n",
    "print(f'f1 score on train set = {f1_train} and f1 score on test set = {f1_test}')\n",
    "print(f'Recall score on train set = {recall_train} and recall score on test set = {recall_test}')\n",
    "print(f'Precision score on train set = {precision_train} and precision score on test set = {precision_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilLr-9aFsYhE"
   },
   "outputs": [],
   "source": [
    "states = [\"AK\", \"AL\", \"AR\", \"AZ\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"HI\", \"IA\",\n",
    "          \"ID\", \"IL\", \"IN\", \"KS\", \"KY\", \"LA\", \"MA\", \"MD\", \"ME\", \"MI\", \"MN\", \"MO\",\n",
    "          \"MS\", \"MT\", \"NC\", \"ND\", \"NE\", \"NH\", \"NJ\", \"NM\", \"NV\", \"NY\", \"OH\", \"OK\",\n",
    "          \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VA\", \"VT\", \"WA\", \"WI\",\n",
    "          \"WV\", \"WY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #improved version-2\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# # Load Data\n",
    "# ##df = pd.read_csv(\"https://raw.githubusercontent.com/ModelEarth/RealityStream/main/input/bees/targets/bees-targets.csv\")\n",
    "# #df_fips = pd.read_csv('../../input/bees/targets/bees-targets.csv')\n",
    "# #df_fips['label'] = df_fips['2022_increase']\n",
    "\n",
    "# # Define Features and Target with One-Hot Encoding\n",
    "# # = df_fips[df_fips['State'] == 'MAINE']  # Filter for Maine\n",
    "# categorical_columns = ['County', 'State', 'Ag District']  # Categorical columns for one-hot encoding\n",
    "\n",
    "# # Apply one-hot encoding\n",
    "# df_encoded = pd.get_dummies(df_full_model, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# # Define features (X) and target (y)\n",
    "# X = df_encoded.drop(columns=['Fips', 'Name', 'label'])  # Drop non-feature columns\n",
    "# y = df_encoded['label']  # Target variable\n",
    "\n",
    "# # Split Dataset\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# # Standardize Features\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# # Perform Grid Search for Random Forest Hyperparameters\n",
    "# rfc = RandomForestClassifier()\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 150],\n",
    "#     'max_depth': [5, 10, 20],\n",
    "#     'min_samples_split': [10, 20],\n",
    "#     'min_samples_leaf': [5, 10]\n",
    "# }\n",
    "# rfcs = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "# rfcs.fit(X_train, y_train)\n",
    "\n",
    "# # Save optimal parameters\n",
    "# n_estimator = rfcs.best_params_['n_estimators']\n",
    "# depth = rfcs.best_params_['max_depth']\n",
    "# min_split = rfcs.best_params_['min_samples_split']\n",
    "# min_leaf = rfcs.best_params_['min_samples_leaf']\n",
    "# print(f'n_estimators = {n_estimator}, max_depth = {depth}, min_samples_split = {min_split}, min_samples_leaf = {min_leaf}')\n",
    "\n",
    "# # Fit a new Random Forest with optimal parameters\n",
    "# opt_rfc = RandomForestClassifier(\n",
    "#     n_estimators=n_estimator,\n",
    "#     max_depth=depth,\n",
    "#     min_samples_split=min_split,\n",
    "#     min_samples_leaf=min_leaf,\n",
    "#     random_state=42\n",
    "# )\n",
    "# opt_rfc.fit(X_train, y_train)\n",
    "# pred_train = opt_rfc.predict(X_train)\n",
    "# pred_test = opt_rfc.predict(X_test)\n",
    "\n",
    "# # Evaluate Model\n",
    "# accu_train = accuracy_score(y_train, pred_train)\n",
    "# accu_test = accuracy_score(y_test, pred_test)\n",
    "\n",
    "# f1_train = f1_score(y_train, pred_train)\n",
    "# f1_test = f1_score(y_test, pred_test)\n",
    "\n",
    "# recall_train = recall_score(y_train, pred_train)\n",
    "# recall_test = recall_score(y_test, pred_test)\n",
    "\n",
    "# precision_train = precision_score(y_train, pred_train)\n",
    "# precision_test = precision_score(y_test, pred_test)\n",
    "\n",
    "# # Print Results\n",
    "# print(f'Accuracy score on train set = {accu_train} and accuracy score on test set = {accu_test}')\n",
    "# print(f'f1 score on train set = {f1_train} and f1 score on test set = {f1_test}')\n",
    "# print(f'Recall score on train set = {recall_train} and recall score on test set = {recall_test}')\n",
    "# print(f'Precision score on train set = {precision_train} and precision score on test set = {precision_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full_model=df_fips[df_fips['State'] == 'MAINE']\n",
    "\n",
    "\n",
    "\n",
    "# #X = df_full_model.drop(columns=['Fips', 'State','county', 'Ag District','Program',''])\n",
    "# X=df_full_model[['FIPS','county','State','Total_Area_km2']]\n",
    "\n",
    "# y = df_full_model['label']\n",
    "\n",
    "\n",
    "# #X.head()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# rfc=RandomForestClassifier()\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 150, 200, 250],\n",
    "#     'max_depth' : [5, 10, 20, 50, 80]\n",
    "# }\n",
    "# rfcs = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "# rfcs.fit(X_train, y_train)\n",
    "# #save optimal parameters\n",
    "# n_estimator = rfcs.best_params_['n_estimators']\n",
    "# depth = rfcs.best_params_['max_depth']\n",
    "# print(f'n_estimators = {n_estimator} and max_depth = {depth}')\n",
    "\n",
    "# #fit a new random forest with optimal parameters\n",
    "# opt_rfc = RandomForestClassifier(n_estimators= n_estimator, max_depth=depth)\n",
    "# opt_rfc.fit(X_train, y_train)\n",
    "# pred_train = opt_rfc.predict(X_train)\n",
    "# pred_test = opt_rfc.predict(X_test)\n",
    "\n",
    "# accu_train = accuracy_score(y_train, pred_train)\n",
    "# accu_test = accuracy_score(y_test, pred_test)\n",
    "\n",
    "# f1_train = f1_score(y_train, pred_train)\n",
    "# f1_test = f1_score(y_test, pred_test)\n",
    "\n",
    "# recall_train = recall_score(y_train, pred_train)\n",
    "# recall_test = recall_score(y_test, pred_test)\n",
    "\n",
    "# precision_train = precision_score(y_train, pred_train)\n",
    "# precision_test = precision_score(y_test, pred_test)\n",
    "# print(f'Accuracy score on train set = {accu_train} and accuracy score on test set = {accu_test}')\n",
    "# print(f'f1 score on train set = {f1_train} and f1 score on test set = {f1_test}')\n",
    "# print(f'Recall score on train set = {recall_train} and recall score on test set = {recall_test}')\n",
    "# print(f'Precision score on train set = {precision_train} and precision score on test set = {precision_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #one hot encoding\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# # Load Data\n",
    "# df = pd.read_csv(\"https://raw.githubusercontent.com/ModelEarth/RealityStream/main/input/bees/targets/bees-targets.csv\")\n",
    "# df_fips = pd.read_csv('../../input/bees/targets/bees-targets.csv')\n",
    "# df_fips['label'] = df_fips['2022_increase']\n",
    "\n",
    "# # Define Features and Target with One-Hot Encoding\n",
    "# df_full_model = df_fips[df_fips['State'] == 'MAINE']  # Filter for Maine\n",
    "# categorical_columns = ['County', 'State', 'Ag District']  # Categorical columns for one-hot encoding\n",
    "\n",
    "# # Apply one-hot encoding\n",
    "# df_encoded = pd.get_dummies(df_full_model, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# # Define features (X) and target (y)\n",
    "# X = df_encoded.drop(columns=['Fips', 'Name', 'label'])  # Drop non-feature columns\n",
    "# y = df_encoded['label']  # Target variable\n",
    "\n",
    "# # Split Dataset\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# # Standardize Features\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# # Perform Grid Search for Random Forest Hyperparameters\n",
    "# rfc = RandomForestClassifier()\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 150, 200, 250],\n",
    "#     'max_depth': [5, 10, 20, 50, 80]\n",
    "# }\n",
    "# rfcs = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "# rfcs.fit(X_train, y_train)\n",
    "\n",
    "# # Save optimal parameters\n",
    "# n_estimator = rfcs.best_params_['n_estimators']\n",
    "# depth = rfcs.best_params_['max_depth']\n",
    "# print(f'n_estimators = {n_estimator} and max_depth = {depth}')\n",
    "\n",
    "# # Fit a new Random Forest with optimal parameters\n",
    "# opt_rfc = RandomForestClassifier(n_estimators=n_estimator, max_depth=depth)\n",
    "# opt_rfc.fit(X_train, y_train)\n",
    "# pred_train = opt_rfc.predict(X_train)\n",
    "# pred_test = opt_rfc.predict(X_test)\n",
    "\n",
    "# # Evaluate Model\n",
    "# accu_train = accuracy_score(y_train, pred_train)\n",
    "# accu_test = accuracy_score(y_test, pred_test)\n",
    "\n",
    "# f1_train = f1_score(y_train, pred_train)\n",
    "# f1_test = f1_score(y_test, pred_test)\n",
    "\n",
    "# recall_train = recall_score(y_train, pred_train)\n",
    "# recall_test = recall_score(y_test, pred_test)\n",
    "\n",
    "# precision_train = precision_score(y_train, pred_train)\n",
    "# precision_test = precision_score(y_test, pred_test)\n",
    "\n",
    "# print(f'Accuracy score on train set = {accu_train} and accuracy score on test set = {accu_test}')\n",
    "# print(f'f1 score on train set = {f1_train} and f1 score on test set = {f1_test}')\n",
    "# print(f'Recall score on train set = {recall_train} and recall score on test set = {recall_test}')\n",
    "# print(f'Precision score on train set = {precision_train} and precision score on test set = {precision_test}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
